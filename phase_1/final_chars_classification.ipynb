{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "from numba import njit,prange\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from commonfunctions import *\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "import joblib\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%run  letters_extraction.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0_1 , model_letters, model_all, model_E_F = 0,0,0,0\n",
    "d = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "winSize = (16,16)\n",
    "blockSize = (8,8)\n",
    "blockStride = (8,8)\n",
    "cellSize = (8,8)\n",
    "nbins = 9\n",
    "\n",
    "hog = cv2.HOGDescriptor(winSize, blockSize, blockStride, cellSize, nbins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_image(img):\n",
    "    image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    image = get_letters(image)[0]\n",
    "    return image\n",
    "\n",
    "def images_resize(directory):\n",
    "    list_target_names = []\n",
    "    list_images = []\n",
    "        \n",
    "    for path, subdirs, files in os.walk(directory):\n",
    "        if(path.startswith(directory + '.')):\n",
    "            continue\n",
    "        files = [f for f in files if not f[0] == '.'] # Ignore '.directory' file\n",
    "        print(path, len(files))\n",
    "        # limit = 600\n",
    "        # if len(files) > limit:\n",
    "        #     files = files[:limit]\n",
    "            \n",
    "        for name in files:\n",
    "            image=cv2.imread(os.path.join(path, name))\n",
    "            image = prepare_image(image)\n",
    "            # image=cv2.resize(image, (100, 100))\n",
    "            list_target_names.append(os.path.basename(path))\n",
    "            list_images.append(image)\n",
    "    \n",
    "    return list_target_names,  list_images \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(directory):\n",
    "    global d;\n",
    "    Name=[]\n",
    "    for file in os.listdir(directory):\n",
    "        Name+=[file]\n",
    "    \n",
    "    #################################\n",
    "    d = defaultdict(int)\n",
    "    co = 0\n",
    "    for x in sorted(os.listdir(directory)):\n",
    "        if not x.startswith('.') and not d[x]:\n",
    "            d[x] = co\n",
    "            co+=1\n",
    "    #########################\n",
    "    target_names,images = images_resize(directory)\n",
    "    #########################\n",
    "    # c = Counter(sorted(target_names))\n",
    "    # target_names = [ d[key] for key in target_names ]\n",
    "    target_names_shuffled, images_shuffled = shuffle(np.array(target_names), np.array(images))\n",
    "    \n",
    "    ############reshaping#############\n",
    "    n_samples,nx,ny= images_shuffled.shape\n",
    "    # n_samples,nx,ny= np.array(images).shape\n",
    "    \n",
    "    images_shuffled2 = np.array([hog.compute(image)  for image in images_shuffled])\n",
    "\n",
    "    images_shuffled2 = images_shuffled2.reshape(n_samples,-1)\n",
    "    # images2 = images2.reshape(n_samples,-1)\n",
    "        \n",
    "    Xtrain, Xtest, ytrain, ytest = train_test_split(images_shuffled2, target_names_shuffled, random_state=0, test_size=0.2)\n",
    "    # Xtrain, Xtest, ytrain, ytest = train_test_split(images2, target_names, train_size= 0.2, random_state=5, shuffle= True)\n",
    "    \n",
    "    return Xtrain, Xtest, ytrain, ytest \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model( directory, filename, verbose = False, is_e_f = False):\n",
    "    \n",
    "    Xtrain, Xtest, ytrain, ytest = load_data(directory)\n",
    "\n",
    "    ####### training #######\n",
    "    if is_e_f :\n",
    "        model = SGDClassifier(loss=\"hinge\", penalty=\"l2\")\n",
    "    else:\n",
    "        model = svm.SVC(gamma = 0.001, C =100)\n",
    "    model.fit(Xtrain, ytrain)\n",
    "    ypred = model.predict(Xtest)\n",
    "    \n",
    "    ########### save model ########\n",
    "    joblib.dump(model, filename)\n",
    "    \n",
    "    if(verbose):\n",
    "        # sns.set(rc={'figure.figsize':(15,12)})\n",
    "        mat = confusion_matrix(ytest, ypred)\n",
    "        # sns.heatmap(mat.T/np.sum(mat.T), annot=True, \n",
    "        #     fmt='.2%', cmap='Blues')\n",
    "        sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False, xticklabels=list(d.keys()), yticklabels=list(d.keys()))\n",
    "        plt.xlabel('true label')\n",
    "        plt.ylabel('predicted label')\n",
    "        plt.show()\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_models(verbose = False):\n",
    "       global model_all;\n",
    "       global model_0_1;\n",
    "       global model_letters;\n",
    "       global model_E_F;\n",
    "       model_all =train_model(directory= './all_symbols/', filename = './saved_models/model_all.sav', verbose= verbose)        \n",
    "       model_0_1 =train_model(directory= './0_1_symbols/', filename = './saved_models/model_0_1.sav', verbose= verbose)\n",
    "       model_letters =train_model(directory= './letters_only_symbols/', filename = './saved_models/model_letters.sav', verbose= verbose)\n",
    "       model_E_F =train_model(directory= './E_F_symbols/', filename = './saved_models/model_E_F.sav', verbose= verbose, is_e_f= True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models(is_expression = True, is_table = True):\n",
    "    \n",
    "    global model_all;\n",
    "    global model_0_1;\n",
    "    global model_letters;\n",
    "    global model_E_F;\n",
    "    if(is_table):\n",
    "        model_0_1 = joblib.load('./saved_models/model_0_1.sav')\n",
    "        model_letters = joblib.load('./saved_models/model_letters.sav')\n",
    "        \n",
    "    \n",
    "    if(is_expression):\n",
    "        model_all = joblib.load('./saved_models/model_all.sav')\n",
    "    \n",
    "    model_E_F = joblib.load('./saved_models/model_E_F.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(img, is_expression=False, is_0_1=False, is_letter=False, verbose = False, is_table = False):\n",
    "    \n",
    "    # print(img)\n",
    "    letters_res = np.array(get_letters(img, verbose= verbose, single_letter=is_table))\n",
    "    hog_images = np.array([hog.compute(image)  for image in letters_res])\n",
    "    # hog_images = np.array([cv2.cornerHarris(image, 2, 3, 0.04)  for image in letters_res])\n",
    "    \n",
    "    # show_images([hog_images])\n",
    "    # hog_images = hog.compute(img)\n",
    "    \n",
    "    if(is_letter):\n",
    "        results =  model_letters.predict(hog_images)\n",
    "        for i, r in enumerate(results):\n",
    "            if r == 'E' or r == 'F':\n",
    "                results[i] = model_E_F.predict([hog_images[i]])[0]\n",
    "        return results\n",
    "    \n",
    "    if(is_0_1):\n",
    "        return model_0_1.predict(hog_images)\n",
    "    \n",
    "    \n",
    "    results =  model_all.predict(hog_images)\n",
    "    for i, r in enumerate(results):\n",
    "        if r == 'E' or r == 'F':\n",
    "            results[i] = model_E_F.predict([hog_images[i]])[0]\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize_models(verbose=True)\n",
    "load_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# letters= cv2.cvtColor(cv2.imread(r\"./test_images/classification1.png\"), cv2.COLOR_BGR2GRAY)\n",
    "# show_images([letters])\n",
    "# letters_res = np.array(get_letters(letters, verbose= False))\n",
    "# show_images(letters_res)\n",
    "\n",
    "# letters_res = np.array([hog.compute(image) for image in letters_res])\n",
    "# print(letters_res.shape)\n",
    "\n",
    "# results = classify( letters, is_expression=True, verbose=True) \n",
    "\n",
    "# print(results)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# letters= cv2.cvtColor(cv2.imread(r\"./test_images/ef.png\"), cv2.COLOR_BGR2GRAY)\n",
    "# show_images([letters])\n",
    "# letters_res = np.array(get_letters(letters, verbose= False))\n",
    "# show_images(letters_res)\n",
    "\n",
    "# results = classify(letters_res, is_expression=True)\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A' 'B' 'C' 'D' 'E' 'F']\n"
     ]
    }
   ],
   "source": [
    "# letters= cv2.cvtColor(cv2.imread(r\"./test_images/failed.png\"), cv2.COLOR_BGR2GRAY)\n",
    "# # show_images([letters])\n",
    "# # letters_res = np.array(get_letters(letters, verbose= False))\n",
    "# # show_images(letters_res)\n",
    "\n",
    "# results = classify(letters, is_expression=True)\n",
    "# print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6aed28f9a78851c43da2b2382d0b32bbb8b6b4eda720ce0dee6d1ffb80b64718"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
